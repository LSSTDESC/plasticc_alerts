{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAsTiCC v2.0 alert simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo of how we can add catalog simulations to LSST alerts in avro forma, which the Rubin project is using. \n",
    "This workbook includes the contributions of Rahul Biswas, Cameron Stockton, Martine Lokken, Alex Gagliano, Gautham Narayan, RenÃ©e Hlozek and the rest of the PLAsTiCC v2.0 team, and the DESC Alerts Topical Team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the README of this repository and then the README of `alert_packet` for setup. This involves installing `alert_packet` in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the examples and codes in `alert_packet` :https://github.com/lsst/alert_packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='alert.jpg', width = 800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.alert.packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from copy import copy\n",
    "import json\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import glob\n",
    "from fastavro import writer, reader\n",
    "HOSTLIB_host=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from sncosmo\n",
    "def read_snana_fits(head_file, phot_file, snids=None, n=None):\n",
    "    \"\"\"Read the SNANA FITS format: two FITS files jointly representing\n",
    "    metadata and photometry for a set of SNe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    head_file : str\n",
    "        Filename of \"HEAD\" (\"header\") FITS file.\n",
    "    phot_file : str\n",
    "        Filename of \"PHOT\" (\"photometry\") FITS file.\n",
    "    snids : list of str, optional\n",
    "        If given, only return the single entry with the matching SNIDs.\n",
    "    n : int\n",
    "        If given, only return the first `n` entries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sne : list of `~astropy.table.Table`\n",
    "        Each item in the list is an astropy Table instance.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If `head_file` contains a column 'SNID' containing strings, leading and\n",
    "    trailing whitespace is stripped from all the values in that column.\n",
    "\n",
    "    If `phot_file` contains a column 'FLT', leading and trailing whitespace\n",
    "    is stripped from all the values in that column.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> sne = read_snana_fits('HEAD.fits', 'PHOT.fits')\n",
    "    >>> for sn in sne:\n",
    "    ...     sn.meta  # Metadata in an OrderedDict.\n",
    "    ...     sn['MJD']  # MJD column\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Should we memmap? Only if we're going to read only a part of the file\n",
    "    memmap = (snids is not None or n is not None)\n",
    "\n",
    "    # Get metadata for all the SNe\n",
    "    head_data = fits.getdata(head_file, 1, view=np.ndarray)\n",
    "    phot_data = fits.getdata(phot_file, 1, view=np.ndarray, memmap=memmap)\n",
    "\n",
    "    # Strip trailing whitespace characters from SNID.\n",
    "    if 'SNID' in head_data.dtype.names:\n",
    "        try:\n",
    "            head_data['SNID'][:] = np.char.strip(head_data['SNID'])\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "    # Check which indicies to return.\n",
    "    if snids is None and n is None:\n",
    "        idx = range(len(head_data))\n",
    "    elif n is None:\n",
    "        if 'SNID' not in head_data.dtype.names:\n",
    "            raise RuntimeError('Specific snids requested, but head file does'\n",
    "                               ' not contain SNID column')\n",
    "        idx = []\n",
    "        for snid in snids:\n",
    "            i = np.flatnonzero(head_data['SNID'] == snid)\n",
    "            if len(i) != 1:\n",
    "                raise RuntimeError('Unique snid requested, but there are '\n",
    "                                   '{0:d} matching entries'.format(len(i)))\n",
    "            idx.append(i[0])\n",
    "    elif snids is None:\n",
    "        idx = range(n)\n",
    "    else:\n",
    "        raise ValueError(\"cannot specify both 'snids' and 'n' arguments\")\n",
    "\n",
    "    # Loop over SNe in HEAD file\n",
    "    sne = []\n",
    "    for i in idx:\n",
    "        meta = odict(zip(head_data.dtype.names, head_data[i]))\n",
    "\n",
    "        j0 = head_data['PTROBS_MIN'][i] - 1\n",
    "        j1 = head_data['PTROBS_MAX'][i]\n",
    "        data = phot_data[j0:j1]\n",
    "        if 'FLT' in data.dtype.names:\n",
    "            data['FLT'][:] = np.char.strip(data['FLT'])\n",
    "        sne.append(Table(data, meta=meta, copy=False))\n",
    "\n",
    "    return sne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These functions will enable us to plot the output from our avro object\n",
    "Example functions taken from https://github.com/ZwickyTransientFacility/ztf-avro-alert/blob/master/notebooks/Working_with_avro_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(packet):\n",
    "    df = pd.DataFrame(packet['diaSource'], index=[0])\n",
    "    df_prv = pd.DataFrame(packet['prvDiaSources'])\n",
    "    return pd.concat([df,df_prv], ignore_index=True)\n",
    "\n",
    "def plot_lightcurve(dflc, days_ago=True):\n",
    "    \n",
    "    filter_color = {'g':'green', 'r':'red', 'u':'pink'}\n",
    "    if days_ago:\n",
    "        now = Time.now().jd\n",
    "        t = dflc.midPointTai - now\n",
    "        xlabel = 'Days Ago'\n",
    "    else:\n",
    "        t = dflc.midPointTai\n",
    "        xlabel = 'Time (JD)'\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for fid, color in filter_color.items():\n",
    "        # plot detections in this filter:\n",
    "        w = (dflc.filterName == fid) & ~dflc.psFlux.isnull()\n",
    "        if np.sum(w):\n",
    "            plt.errorbar(t[w],dflc.loc[w,'apFlux'], dflc.loc[w,'apFluxErr'],fmt='.',color=color)\n",
    "            \n",
    "        else:\n",
    "            plt.errorbar(t[w],dflc.loc[w,'apFlux'], dflc.loc[w,'apFluxErr'],fmt='.',color=color)\n",
    "                \n",
    "        #wnodet = (dflc.fid == fid) & dflc.magpsf.isnull()\n",
    "        #if np.sum(wnodet):\n",
    "         #   plt.scatter(t[wnodet],dflc.loc[wnodet,'diffmaglim'], marker='v',color=color,alpha=0.25)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read in the schema from the Rubin alert.packet \n",
    "In this case we are modifying the usual alert schema to have (lots of) additional information in it. The expected list of host information will be more like host magnitudes and host errors, the light profile moments and PSF information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those interested in modified alert schemas, this is included in the repo as an example, modified from the `alert_packet' repo\n",
    "schema = lsst.alert.packet.Schema.from_file('./plasticc_schema/lsst.v4_1.alert.avsc','lsst.v4_1.alert')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in an example json file that matches our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./plasticc_schema/sample_data/')\n",
    "with open(path/'plasticc.json') as f:\n",
    "    alert_data = json.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What does the alert data schema look like?\n",
    "It has one diaSource object for the current epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_data['diaSource']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about previous diaSources?\n",
    "The previous diaSources for this diaObject are also nested in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_data['prvDiaSources']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This alert schema is just a dictionary: next we will read data from SNANA and write it to the values of the correct keys. We start by pulling off the first record to overwrite with SNANA information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasrc = alert_data['prvDiaSources'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking an SNANA file and porting information to alert\n",
    "We will pull off models from the PLAsTiCC v2.0 DDF simulation, and assign the info to the alert packet. Note that we are adding information that isn't in the defined in the original LSST schema for this round. The following code takes the photometry and header files from SNANA and pushes them to a diaSource object for an index/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_diasrc_from_fits(sn, my_diasrc,hostlib_flag=True,i=0):\n",
    "    \n",
    "        my_diasrc['filterName'] = sn['BAND'][i]     \n",
    "        my_diasrc['apFlux'] = sn['FLUXCAL'][i]\n",
    "        my_diasrc['apFluxErr'] = sn['FLUXCALERR'][i]\n",
    "        my_diasrc['snr'] = sn['FLUXCAL'][i]/sn['FLUXCALERR'][i]\n",
    "        my_diasrc['midPointTai'] = sn['MJD'][i]\n",
    "    \n",
    "        # General properties\n",
    "        my_diasrc['ra'] = sn.meta['RA']\n",
    "        my_diasrc['decl'] = sn.meta['DEC']\n",
    "        my_diasrc['nobs'] = sn.meta['NOBS']\n",
    "        my_diasrc['mwebv'] = sn.meta['MWEBV']\n",
    "        my_diasrc['mwebv_err'] = sn.meta['MWEBV_ERR']\n",
    "        my_diasrc['z_final'] = sn.meta['REDSHIFT_FINAL']\n",
    "        my_diasrc['z_final_err'] = sn.meta['REDSHIFT_FINAL_ERR']\n",
    "        my_diasrc['hostgal_ra'] = sn.meta['HOSTGAL_RA']\n",
    "        my_diasrc['hostgal_dec'] = sn.meta['HOSTGAL_DEC']\n",
    "        my_diasrc['hostgal_snsep']= sn.meta['HOSTGAL_SNSEP']\n",
    "   \n",
    "        \n",
    "        my_diasrc['hostgal_z']=sn.meta['HOSTGAL_SPECZ']\n",
    "        my_diasrc['hostgal_z_err']=sn.meta['HOSTGAL_SPECZ_ERR']   \n",
    "        my_diasrc['hostgal_mag_u']= sn.meta['HOSTGAL_MAG_u']\n",
    "        my_diasrc['hostgal_mag_g']= sn.meta['HOSTGAL_MAG_g']\n",
    "        my_diasrc['hostgal_mag_r']= sn.meta['HOSTGAL_MAG_r']\n",
    "        my_diasrc['hostgal_mag_i']= sn.meta['HOSTGAL_MAG_i']\n",
    "        my_diasrc['hostgal_mag_z']= sn.meta['HOSTGAL_MAG_z']\n",
    "        my_diasrc['hostgal_mag_Y']= sn.meta['HOSTGAL_MAG_Y']\n",
    "        my_diasrc['hostgal_magerr_u']= sn.meta['HOSTGAL_MAGERR_u']\n",
    "        my_diasrc['hostgal_magerr_g']= sn.meta['HOSTGAL_MAGERR_g']\n",
    "        my_diasrc['hostgal_magerr_r']= sn.meta['HOSTGAL_MAGERR_r']\n",
    "        my_diasrc['hostgal_magerr_i']= sn.meta['HOSTGAL_MAGERR_i']\n",
    "        my_diasrc['hostgal_magerr_z']= sn.meta['HOSTGAL_MAGERR_z']\n",
    "        \n",
    "        if hostlib_flag:\n",
    "            # properties of the host galaxy\n",
    "           # print('using HOSTLIB values')\n",
    "            #my_diasrc['ellipticity'] = head[1].data['SIM_HOSTLIB(TOTAL_ELLIPTICITY)'][0]\n",
    "            my_diasrc['ellipticity'] = sn.meta['HOSTGAL_DDLR'] #remove - testing only\n",
    "            #my_diasrc['GHOST_ID']  = head[1].data['SIM_HOSTLIB(galaxy_id)'][i] #testing\n",
    "            #my_diasrc['size'] = head[1].data['SIM_HOSTLIB(SIZE_TRUE)'][0]\n",
    "            my_diasrc['size'] = sn.meta['HOSTGAL_DDLR'] # remove - testing only\n",
    "   \n",
    "        return my_diasrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the data from a particular SNANA model. In this case we are using a small SNANA simulation that includes the host properties (from work by Martine Lokken and Alex Gagliano). The full PLAsTiCC suite will contain alerts for a range of different objects from a variety of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir='/global/cscratch1/sd/rhlozek/alerts/plasticc_alerts/Examples'\n",
    "os.chdir(savedir)\n",
    "retval = os.getcwd()\n",
    "#simdir='/global/cscratch1/sd/kessler/SNANA_LSST_SIM/GSN_LSST_DDF/'\n",
    "simdir='../hostSims/'\n",
    "os.chdir(simdir)\n",
    "modelname = glob.glob('*MODEL*')\n",
    "    \n",
    "#print(alert_data_orig['prvDiaSources'][0])\n",
    "num_sne =2 #how many supernova alerts you want to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(retval)\n",
    "print(f\"Running alerts for the model list: {modelname}\")\n",
    "\n",
    "path = Path('plasticc_schema/sample_data')\n",
    "with open(path/'plasticc.json') as f:\n",
    "    alert_data_orig = json.load(f)\n",
    "    \n",
    "#print(alert_data_orig)\n",
    "    \n",
    "fig = plt.figure(figsize=(12,60))\n",
    "number_of_subplots=len(modelname)\n",
    "#print(number_of_subplots)\n",
    "\n",
    "for countm,name in enumerate(modelname):\n",
    "    #print(name)\n",
    "    # Open the photometry file and the header files\n",
    "    name_head=simdir+'/'+name+'/'+'%s-0001_HEAD.FITS.gz'%name\n",
    "    name_phot=simdir+'/'+name+'/'+'%s-0001_PHOT.FITS.gz'%name\n",
    "    \n",
    "    sne = read_snana_fits(name_head, name_phot)\n",
    "    \n",
    "    \n",
    "    #print(sne[0].meta)\n",
    "    #print('-----')\n",
    "    for iterNum,sn in enumerate(sne[0:num_sne]):\n",
    "        #print(sn.colnames)\n",
    "        ra = sn.meta['RA']\n",
    "        mjd = sn['MJD']\n",
    "        #print(sn['FLUXCALERR'])\n",
    "        alert = copy(alert_data_orig)\n",
    "    \n",
    "        diasrc = alert_data_orig['prvDiaSources'][0]\n",
    "        my_diasrc = copy(diasrc)\n",
    "        alert = copy(alert_data_orig)\n",
    "        alert['prvDiaSources'].clear()\n",
    "\n",
    "\n",
    "        # Make a dummy source ID and import additional information to the diaSource\n",
    "        my_diasrc['diaSourceId'] = np.int64(28132306237521+1000*np.random.uniform())\n",
    "        my_diasrc = import_diasrc_from_fits(sn,my_diasrc,HOSTLIB_host,i=0)\n",
    "        alert['diaSource'] = my_diasrc\n",
    "        \n",
    "        for j, day in enumerate(mjd):\n",
    "            my_diasrc = copy(diasrc)\n",
    "            my_diasrc['diaSourceId'] = my_diasrc['diaSourceId']+j+1\n",
    "            plt.figure(iterNum*100)\n",
    "            #print(mjd[j],sn['FLUXCAL'][j])\n",
    "            print(sn['FLUXCALERR'][j])\n",
    "            plt.scatter(day,sn['FLUXCAL'][j], marker='o' )\n",
    "            my_diasrc = import_diasrc_from_fits(sn,my_diasrc,HOSTLIB_host,i=j)\n",
    "            alert['prvDiaSources'].append(alert['diaSource'])\n",
    "\n",
    "        # serialize the alert    \n",
    "        avro_bytes = schema.serialize(alert)\n",
    "        messg = schema.deserialize(avro_bytes)\n",
    "        \n",
    "\n",
    "        with open(\"plasticcAlert_%s_%i.avro\"%(name,iterNum), \"wb\") as f:\n",
    "            schema.store_alerts(f, [alert])\n",
    "        print(f\"Saving model {name} as plasticcAlert_{name}_{iterNum}.avro\")\n",
    "\n",
    "    print(f\"Done saving models for {modelname}\")\n",
    "print(f\"Done saving all models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for countm,name in enumerate(modelname):\n",
    "    sne=glob.glob(\"*{}*.avro\".format(name))\n",
    "    print(sne)\n",
    "    for cn, sn in enumerate(sne):\n",
    "        fname= savedir+'/'+\"plasticcAlert_%s_%i.avro\"%(name,cn)\n",
    "        print(f\"Reading {fname}\")\n",
    "        with open(fname,'rb') as f:\n",
    "            freader = reader(f)\n",
    "            for alert in freader:\n",
    "                dflc = make_dataframe(alert)\n",
    "                plot_lightcurve(dflc)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
