{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAsTiCC v2.0 alert simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo of how we can add catalog simulations to LSST alerts in avro forma, which the Rubin project is using. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the README of this repository and then the README of `alert_packet` for setup. This involves installing `alert_packet` in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the examples and codes in `alert_packet` :https://github.com/lsst/alert_packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.alert.packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from copy import copy\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import glob\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n",
    "\n",
    "HOSTLIB_host=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These functions will enable us to plot the output from our avro object\n",
    "Example functions taken from https://github.com/ZwickyTransientFacility/ztf-avro-alert/blob/master/notebooks/Working_with_avro_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(packet):\n",
    "    df = pd.DataFrame(packet['diaSource'], index=[0])\n",
    "    df_prv = pd.DataFrame(packet['prvDiaSources'])\n",
    "    return pd.concat([df,df_prv], ignore_index=True)\n",
    "\n",
    "def plot_lightcurve(dflc, days_ago=True):\n",
    "    \n",
    "    filter_color = {'g':'green', 'r':'red', 'u':'pink'}\n",
    "    if days_ago:\n",
    "        now = Time.now().jd\n",
    "        t = dflc.midPointTai - now\n",
    "        xlabel = 'Days Ago'\n",
    "    else:\n",
    "        t = dflc.midPointTai\n",
    "        xlabel = 'Time (JD)'\n",
    "    \n",
    "    plt.figure()\n",
    "    for fid, color in filter_color.items():\n",
    "        # plot detections in this filter:\n",
    "        w = (dflc.filterName == fid) & ~dflc.psFlux.isnull()\n",
    "        if np.sum(w):\n",
    "            plt.errorbar(t[w],dflc.loc[w,'apFlux'], dflc.loc[w,'apFluxErr'],fmt='.',color=color)\n",
    "        #wnodet = (dflc.fid == fid) & dflc.magpsf.isnull()\n",
    "        #if np.sum(wnodet):\n",
    "         #   plt.scatter(t[wnodet],dflc.loc[wnodet,'diffmaglim'], marker='v',color=color,alpha=0.25)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read in the schema from the Rubin alert.packet \n",
    "In this case we are modifying the usual alert schema to have (lots of) additional information in it. The expected list of host information will be more like host magnitudes and host errors, the light profile moments and PSF information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those interested in modified alert schemas, this is included in the repo as an example, modified from the `alert_packet' repo\n",
    "schema = lsst.alert.packet.Schema.from_file('./plasticc_schema/lsst.v4_1.alert.avsc','lsst.v4_1.alert')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in an example json file that matches our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./plasticc_schema/sample_data/')\n",
    "with open(path/'plasticc.json') as f:\n",
    "    alert_data = json.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What does the alert data schema look like?\n",
    "It has one diaSource object for the current epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_data['diaSource']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about previous diaSources?\n",
    "The previous diaSources for this diaObject are also nested in the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_data['prvDiaSources']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This alert schema is just a dictionary: next we will read data from SNANA and write it to the values of the correct keys. We start by pulling off the first record to overwrite with SNANA information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diasrc = alert_data['prvDiaSources'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking an SNANA file and porting information to alert\n",
    "We will pull off models from the PLAsTiCC v2.0 DDF simulation, and assign the info to the alert packet. Note that we are adding information that isn't in the defined in the original LSST schema for this round. The following code takes the photometry and header files from SNANA and pushes them to a diaSource object for an index/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_diasrc_from_fits(head, phot,my_diasrc,hostlib_flag=False,i=0):\n",
    "    \n",
    "        my_diasrc['filterName'] = phot[1].data['FLT'][i]     \n",
    "        my_diasrc['apFlux'] = phot[1].data['FLUXCAL'][i]\n",
    "        my_diasrc['apFluxErr'] = phot[1].data['FLUXCALERR'][i]\n",
    "        my_diasrc['snr'] = phot[1].data['FLUXCAL'][i]/phot[1].data['FLUXCALERR'][i]\n",
    "        my_diasrc['midPointTai'] = phot[1].data['MJD'][i]\n",
    "    \n",
    "        # General properties\n",
    "        my_diasrc['ra'] = head[1].data['RA'][i]\n",
    "        my_diasrc['decl'] = head[1].data['DEC'][i]\n",
    "        my_diasrc['nobs'] = head[1].data['NOBS'][i]\n",
    "        my_diasrc['mwebv'] = head[1].data['MWEBV'][i]\n",
    "        my_diasrc['mwebv_err'] = head[1].data['MWEBV_ERR'][i]\n",
    "        my_diasrc['z_final'] = head[1].data['REDSHIFT_FINAL'][i]\n",
    "        my_diasrc['z_final_err'] = head[1].data['REDSHIFT_FINAL_ERR'][i]\n",
    "        \n",
    "        if hostlib_flag:\n",
    "        \n",
    "                # properties of the host galaxy\n",
    "            #print('using HOSTLIB values')\n",
    "            my_diasrc['hostgal_logmass'] = head[1].data['SIM_HOSTLIB(LOGMASS_OBS)'][0]\n",
    "            my_diasrc['hostgal_sfr']= head[1].data['SIM_HOSTLIB(STAR_FORMATION_RATE)'][0]\n",
    "            my_diasrc['ellipticity'] = head[1].data['SIM_HOSTLIB(TOTAL_ELLIPTICITY)'][0]\n",
    "            my_diasrc['size'] = head[1].data['SIM_HOSTLIB(SIZE_TRUE)'][0]\n",
    "            my_diasrc['hostgal_z'] = head[1].data['HOSTGAL_SPECZ'][0]\n",
    "            my_diasrc['hostgal_mag_u']= head[1].data['HOSTGAL_MAG_u'][0] #check\n",
    "            my_diasrc['hostgal_mag_g']= head[1].data['SIM_HOSTLIB(MAG_TRUE_g_SDSS_z0)'][0]\n",
    "            my_diasrc['hostgal_mag_r']= head[1].data['SIM_HOSTLIB(MAG_TRUE_r_SDSS_z0)'][0]   \n",
    "            my_diasrc['hostgal_mag_i']= head[1].data['SIM_HOSTLIB(MAG_TRUE_i_SDSS_z0)'][0]  \n",
    "            my_diasrc['hostgal_mag_z']= head[1].data['SIM_HOSTLIB(MAG_TRUE_z_SDSS_z0)'][0]\n",
    "            \n",
    "        else:\n",
    "            #print('using uncorrelated SNANA values')\n",
    "            my_diasrc['hostgal_logmass']= head[1].data['HOSTGAL_LOGMASS'][0]\n",
    "            my_diasrc['hostgal_z']=head[1].data['HOSTGAL_SPECZ'][0]\n",
    "            my_diasrc['hostgal_z_err']=head[1].data['HOSTGAL_SPECZ_ERR'][0]\n",
    "            my_diasrc['hostgal_ssfr']= head[1].data['HOSTGAL_sSFR'][0]\n",
    "            my_diasrc['hostgal_ssfr_err']= head[1].data['HOSTGAL_sSFR_ERR'][0]\n",
    "            my_diasrc['hostgal_mag_u']= head[1].data['HOSTGAL_MAG_u'][0]\n",
    "            my_diasrc['hostgal_mag_g']= head[1].data['HOSTGAL_MAG_g'][0]\n",
    "            my_diasrc['hostgal_mag_r']= head[1].data['HOSTGAL_MAG_r'][0]\n",
    "            my_diasrc['hostgal_mag_i']= head[1].data['HOSTGAL_MAG_i'][0]\n",
    "            my_diasrc['hostgal_mag_z']= head[1].data['HOSTGAL_MAG_z'][0]\n",
    "            \n",
    "        # Common to both\n",
    "        my_diasrc['hostgal_ra'] = head[1].data['HOSTGAL_RA'][0]\n",
    "        my_diasrc['hostgal_dec'] = head[1].data['HOSTGAL_DEC'][0]\n",
    "        my_diasrc['hostgal_snsep']= head[1].data['HOSTGAL_SNSEP'][0]\n",
    "        my_diasrc['hostgal_magerr_u']= head[1].data['HOSTGAL_MAGERR_u'][0]\n",
    "        my_diasrc['hostgal_magerr_g']= head[1].data['HOSTGAL_MAGERR_g'][0]\n",
    "        my_diasrc['hostgal_magerr_r']= head[1].data['HOSTGAL_MAGERR_r'][0]\n",
    "        my_diasrc['hostgal_magerr_i']= head[1].data['HOSTGAL_MAGERR_i'][0]\n",
    "        my_diasrc['hostgal_magerr_z']= head[1].data['HOSTGAL_MAGERR_z'][0]\n",
    "        my_diasrc['hostgal_logmass_err']= head[1].data['HOSTGAL_LOGMASS_ERR'][0]\n",
    "\n",
    "        return my_diasrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the data from a particular SNANA model. In this case we are using a small SNANA simulation that includes the host properties (from work by Martine Lokken and Alex Gagliano). The full PLAsTiCC suite will contain alerts for a range of different objects from a variety of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('plasticc_schema/sample_data')\n",
    "with open(path/'plasticc.json') as f:\n",
    "    alert_data_orig = json.load(f)\n",
    "\n",
    "savedir='/global/cscratch1/sd/rhlozek/alerts/plasticc_alerts/Examples'\n",
    "os.chdir(savedir)\n",
    "retval = os.getcwd()\n",
    "#simdir='/global/cscratch1/sd/kessler/SNANA_LSST_SIM/GSN_LSST_DDF/'\n",
    "simdir='../hostSims/'\n",
    "os.chdir(simdir)\n",
    "modelname = glob.glob('*MODEL*')\n",
    "os.chdir(retval)\n",
    "print(f\"Running alerts for the model list: {modelname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,60))\n",
    "number_of_subplots=len(modelname)\n",
    "#print(number_of_subplots)\n",
    "\n",
    "# Some objects will not have data, so as we iterate over objects we keep track of those that were successfully written to file\n",
    "keep = -9*np.ones(len(modelname))\n",
    "\n",
    "\n",
    "for countm,name in enumerate(modelname):\n",
    "    print(name)\n",
    "    # Open the photometry file and the header files\n",
    "    name_head=simdir+'/'+name+'/'+'%s-0001_HEAD.FITS.gz'%name\n",
    "    name_phot=simdir+'/'+name+'/'+'%s-0001_PHOT.FITS.gz'%name\n",
    "    \n",
    "    \n",
    "#     name_head=simdir+name+'/'+'GSN_LSST_DDF_NONIaMODEL0-0001_HEAD.FITS.gz'\n",
    "#     name_phot=simdir+name+'/'+'GSN_LSST_DDF_NONIaMODEL0-0001_PHOT.FITS.gz'\n",
    "    \n",
    "    \n",
    "    head = fits.open(name_head)\n",
    "    head_cols=head[1].columns\n",
    "    phot = fits.open(name_phot)\n",
    "    phot_cols=phot[1].columns\n",
    "\n",
    "    # now take header information off the photometry just to plot the models\n",
    "    mjd = phot[1].data['MJD']\n",
    "    mag = phot[1].data['SIM_MAGOBS']\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        # The SNANA objects are stored with -777 between objects in a given model. \n",
    "        # For this demo we pull off only the first object in the model\n",
    "        bound = np.where(mjd==-777)[0][0]-1\n",
    "        \n",
    "        if number_of_subplots==1:\n",
    "             ax1 = plt.subplots(1,1)\n",
    "        else: \n",
    "            ax1 = plt.subplot(number_of_subplots,1,countm+1)\n",
    "\n",
    "        plt.plot(mjd, mag,'.')\n",
    "        plt.text(60600,45, '%s'%name)\n",
    "        plt.axis([60500,64000, 20,50])\n",
    "\n",
    "        # copy the original alert data and clear all old sources\n",
    "        alert = copy(alert_data_orig)\n",
    "        diasrc = alert_data_orig['prvDiaSources'][0]\n",
    "        my_diasrc = copy(diasrc)\n",
    "        alert = copy(alert_data_orig)\n",
    "        alert['prvDiaSources'].clear()\n",
    "        \n",
    "        \n",
    "        # Make a dummy source ID and import additional information to the diaSource\n",
    "        my_diasrc['diaSourceId'] = np.int(28132306237521+1000*np.random.uniform())\n",
    "        my_diasrc = import_diasrc_from_fits(head, phot,my_diasrc,HOSTLIB_host,i=0)        \n",
    "        alert['diaSource'] = my_diasrc\n",
    "        \n",
    "        # Writing the g band light curves to a dummy alert for now\n",
    "        ginds = np.where(phot[1].data['FLT'][0:bound]=='g')[0]\n",
    "        \n",
    "        # for each item in the light curve, create a new diaSource or \n",
    "        # append the list of previous diaSources\n",
    "        for count, i in enumerate(ginds):\n",
    "            #print(count,i)\n",
    "            my_diasrc = copy(diasrc)\n",
    "            my_diasrc['diaSourceId'] = my_diasrc['diaSourceId']+count+1\n",
    "            my_diasrc = import_diasrc_from_fits(head, phot,my_diasrc,HOSTLIB_host,i)\n",
    "            alert['prvDiaSources'].append(alert['diaSource'])\n",
    "            alert['diaSource'] = my_diasrc\n",
    "\n",
    "        # serialize the alert    \n",
    "        avro_bytes = schema.serialize(alert)\n",
    "        messg = schema.deserialize(avro_bytes)\n",
    "        iterNum=0\n",
    "        \n",
    "        # keep a record of if we indeed have a viable light curve to save\n",
    "        keep[countm]=int(countm)\n",
    "        with open(\"plasticcAlert_%s_%i.avro\"%(name,iterNum), \"wb\") as f:\n",
    "            schema.store_alerts(f, [alert])\n",
    "        print(f\"Saving model {name} as plasticcAlert_{name}_{iterNum}.avro\")\n",
    "    except:\n",
    "        print(f\"This model {name} seems to have no data\")\n",
    "        keep[countm]=int(0)\n",
    "    print(f\"Done saving models\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.where(keep!=-9)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(keep)\n",
    "for count in keep:\n",
    "    iterNum=0\n",
    "    print(count, modelname[count])\n",
    "    \n",
    "    fname= savedir+'/'+\"plasticcAlert_%s_%i.avro\"%(modelname[count],iterNum)\n",
    "    print(f\"Reading {fname}\")\n",
    "    with open(fname,'rb') as f:\n",
    "        freader = DataFileReader(f,DatumReader())\n",
    "        for alert in freader:\n",
    "            dflc = make_dataframe(alert)\n",
    "            plot_lightcurve(dflc)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
